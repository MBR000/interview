前端学习冲冲

目录

- HTML（HTML5.3）
- CSS（模块）
- JS（ES6）
- VUE
- React
- 手写算法、实现
- 计算机网络
- 操作系统
- 浏览器
- 工具/插件
- 构建工具和工程化
- **进阶技能**

# 前沿理论

## 依赖管理

### npm

npm 可以说是最早的依赖安装 cli，我们先来看一下 npm 是怎么样安装依赖的

1. 发出 npm install 命令；
2. npm 向 registry 查询模块压缩包的网址；
3. 下载压缩包，存放在 ~/.npm 目录；
4. 将压缩包解压到当前项目的 node_modules 目录。

#### npm2

**嵌套地狱**

`npm2` 安装依赖的时候比较简单直接，直接按照包依赖的树形结构下载填充本地目录结构，也就是**嵌套的 node_modules 结构**，直接依赖会平铺在 node_modules 下，子依赖嵌套在直接依赖的 node_modules 中。

#### **npm3**

**扁平化嵌套、不确定性、依赖分身、幽灵依赖**

针对 npm2 存在的问题，npm3 提出新的解决方案，将依赖进行展平，也就是扁平化。

npm v3 将子依赖「提升」(hoist)，采用**扁平的 node_modules 结构**，子依赖会尽量平铺安装在主依赖项所在的目录中。

举个例子，项目依赖了 A 和 C，而 A 依赖了 B@1.0.0，而且 C 还依赖了 B@2.0.0：

```
node_modules
├── A@1.0.0
├── B@1.0.0
└── C@1.0.0
     └── node_modules
          └── B@2.0.0
```

可以看到 A 的子依赖的 B@1.0 不再放在 A 的 node_modules 下了，而是与 A 同层级。而 C 依赖的 B@2.0 因为版本号原因还是放到了 C 的 node_modules 下。

这样不会造成大量包的重复安装，依赖的层级也不会太深，解决了依赖地狱问题。

**那为什么不把 B@2.0.0 提到 node_modules 而是 B@1.0.0 呢？而且将 B 直接提取到我们的 node_modules，是不是意味着我们可以在代码直接引用 B 包？由此引出我们下面的问题：**

①**不确定性**

我们对于这种处理方式其实很容易有一个疑问，如果我同时引用了同一个包的多个不同版本，会帮我把哪个包提出来，同时我每次 `npm i` 之后提出来的包版本都是一样的吗？这也意味着同样的 package.json 文件，install 依赖后可能不会得到同样的 node_modules 目录结构。

②**幽灵依赖** 

什么叫做幽灵依赖，也就是我的 package.json 没有指明这个包，但实际项目使用了这个包，且这个包因为扁平化嵌套导致了可以直接使用，也就是**非法访问**，最经常碰到的就是 dayjs 这个包。

比如我的项目使用了 arco，但是 arco 的子依赖有 dayjs，那么根据扁平化，dayjs 就会被放在 node_modules 的首层。**但是存在很大的问题，一旦 arco 去掉了这个子依赖，那么我们的代码就直接报错了。**

③**依赖分身**

假设继续再安装依赖 B@1.0 的 D 模块和依赖 @B2.0 的 E 模块，此时：

- A 和 D 依赖 B@1.0
- C 和 E 依赖 B@2.0

以下是提升 B@1.0 的 node_modules 结构：

```
node_modules
├── A@1.0.0
├── B@1.0.0
├── D@1.0.0
├── C@1.0.0
│    └── node_modules
│         └── B@2.0.0
└── E@1.0.0
      └── node_modules
           └── B@2.0.0
```

可以看到 B@2.0 会被安装两次，实际上无论提升 B@1.0 还是 B@2.0，都会存在重复版本的 B 被安装，这两个重复安装的 B 就叫 doppelgangers。

而且虽然看起来模块 C 和 E 都依赖 B@2.0，但其实引用的不是同一个 B，假设 B 在导出之前做了一些缓存或者副作用，那么使用者的项目就会因此而出错

#### npm install

npm3 以上的版本安装依赖的步骤：

- **检查配置**：读取 `npm config` 和 `.npmrc` 配置，比如配置镜像源。

- **确定依赖版本，构建依赖树**：检查是否存在 `package-lock.json`。若存在，进行版本比对，处理方式和 npm 版本有关，根据最新 npm 版本处理规则，版本能兼容按照 package-lock 版本安装，反之按照 package.json 版本安装；若不存在，根据 `package.json` 确定依赖包信息。
- **检查缓存或下载**：判断是否存在缓存。若存在，将对应缓存解压到 node_modules 下，生成 `package-lock.json`；若不存在，则下载资源包，验证包完整性并添加至缓存，之后解压到 node_modules 下，生成 `package-lock.json`。

**安装速度慢，没有解决扁平化带来的算法复杂性、幽灵依赖等本质问题；**

### yarn

#### 并行安装

无论何时 npm 或者 yarn 需要安装包，都会产出一系列的任务。使用 npm 时，这些任务按包顺序执行，也就是只有当一个包全部安装完成后，才会安装下一个。

Yarn 通过并行操作最大限度地提高资源利用率，以至于再次下载的时候安装时间比之前更快。npm5 之前是等上一个安装完后再执行下一个，串行下载。

#### 最重要的 - yarn.lock 文件

npm 的策略可能会导致两台设备使用同样的 `package.json` 文件，但安装了不同版本的包，这可能导致故障。

举个例子，无法保证一致性，拉取的 packages 可能版本不同，例如：`5.0.3`、`~5.0.3`、`^5.0.3`。

- `5.0.3` 表示安装指定的 5.0.3 版本
- `～ 5.0.3` 表示安装 5.0.X 中最新的版本
- `^5.0.3` 表示安装 5.X.X 中最新的版本

针对这个问题，yarn 推出了 lock 文件。

为了防止拉取到不同的版本，yarn 有一个锁定文件 (lock file) 记被确切安装上的模块的版本号。每次只要新增了一个模块，yarn 就会创建（或更新）yarn.lock 这个文件。这样就保证了每一次拉取同一个项目依赖时，使用的都是一样的模块版本。

`yarn.lock` 只包含版本锁定，并不确定依赖结构，需要结合 `package.json` 确定依赖结构。这个在 install 的过程会进行详细解答。

`yarn.lock` 锁文件把所有的依赖包都扁平化的展示了出来，对于同名包但是 semver 不兼容的作为不同的字段放在了 `yarn.lock` 的同一级结构中。（比如同一个包的不同版本，就是并列放在一起的）

#### Yarn install

执行 `yarn install` 后会经过五个阶段：

- Validating package.json（检查 package.json）：检查运行环境。
- Resolving packages（解析包）：整合依赖信息。
- Fetching packages（获取包）：获取依赖包到缓存中。
- Linking dependencies（连接依赖）：复制依赖到 node_modules。
- Building fresh packages（构建安装）：执行 install 阶段的 scripts。

### pnpm

`pnpm` 代表 performant（高性能的）`npm`，如 `pnpm` 官方介绍，它是：`速度快、节省磁盘空间的软件包管理器`，pnpm 本质上就是一个包管理器，它的两个优势在于:

- 包安装速度极快；
- 磁盘空间利用非常高效。

**这与 pnpm 独特的 link 机制有关。**

#### link 机制

计算机里面一个叫做 Hard link的机制，`hard link` 使得用户可以通过不同的路径引用方式去找到某个文件。pnpm 会在全局的 store 目录里存储项目 `node_modules` 文件的 `hard links`。

`hard links` 可以理解为源文件的副本，**项目里安装的其实是副本，它使得用户可以通过路径引用查找到源文件。同时，pnpm 会在全局 store 里存储硬链接**，不同的项目可以从全局 store 寻找到同一个依赖，大大地节省了磁盘空间。

`hard links` 指通过索引节点来进行连接。比如：A 是 B 的硬链接（A 和 B 都是文件名），则 A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号相同，即一个 inode 节点对应两个不同的文件名，两个文件名指向同一个文件，A 和 B 对文件系统来说是完全平等的，都是副本。删除其中任何一个都不会影响另外一个的访问。

#### Symbolic link

**Symbolic link**也叫软连接，可以理解为**快捷方式**，pnpm 可以通过它找到对应磁盘目录下的依赖地址。软链接文件只是其源文件的一个标记，当删除了源文件后，链接文件不能独立存在，虽然仍保留文件名，但却不能查看软链接文件的内容了。

#### pnpm 的 link

包是从全局 store 硬连接到虚拟 store 的，这里的虚拟 store 就是 node_modules/.pnpm。也就是说，所有的依赖都是从全局 store 硬连接到了 node_modules/.pnpm 下，然后之间通过软链接来相互依赖。

通过包名 + 版本号，指向唯一的全局缓存。然后 node_modules 下的包指向 .pnpm 下对应的特定版本的包

### 总结pnpm

#### 优势

这套全新的机制设计地十分巧妙，不仅兼容 node 的依赖解析，同时也解决了以下问题：

1. 幽灵依赖问题：所有的依赖会平铺在 node_modules 下，子依赖全在.pnpm里面，不会被提升，不会产生幽灵依赖。
2. 依赖分身问题：相同的依赖**只会在全局 store 中安装一次**。项目中的都是源文件的副本，几乎不占用任何空间，没有了依赖分身。
3. 最大的优点是节省磁盘空间，一个包全局只保存一份，剩下的都是软硬连接。

#### 不足之处

1. 全局 hardlink 也会导致一些问题，比如改了 link 的代码，所有项目都受影响；对 postinstall 不友好；在 postinstall 里修改了代码，可能导致其他项目出问题。**pnpm 默认就是 copy on write**[5]，但是 copy on write 这个配置对 mac 没生效，其实是 node 没支持导致的
2. 由于 pnpm 创建的 node_modules 依赖软链接，因此在不支持软链接的环境中，无法使用 pnpm，比如 Electron 应用

## 微前端

### 前言

当前，基于 **vue**、**react**、**angular** 的**单页应用开发模式**已经成为业界主流。受益于它们丰富的生态，我们可以使用这些技术快速构建一个新的应用，迅速响应市场。随着公司业务的不断发展，应用开始变得庞大臃肿，逐渐成为一个**巨石应用**，难以维护不说，每次开发、上线新需求时还需要花费不少的时间来构建项目，对开发人员的开发效率和体验都造成了不好的影响。

应用拆分能给我们带来便利，但同时也给我们带来了新的挑战，那就是**应用的聚合**。对于客户来说，他们在使用我们的产品时，更希望呈现在自己面前的是一个完整的应用，而不是分散的多个子应用。因此我们需要选择一个合适的方案，能兼容不同的技术栈，将已经拆分的子应用重新聚合。

而**微前端**，正是这样一个合适的方案，来帮助我们面对上述挑战。

### 介绍

**微前端**，早已是一个老生常谈的概念，它于 2016 年首次出现在 [ThoughtWorks Technology Radar](https://link.juejin.cn?target=https%3A%2F%2Fwww.thoughtworks.com%2Fradar%2Ftechniques%2Fmicro-frontends) 上，将后端**微服务**的概念扩展到了前端世界。

**微服务**，具体来讲，就是**将一个单体应用，按照一定的规则拆分为一组服务**。这些服务，各自拥有自己的仓库，可以独立开发、独立部署，有独立的边界，可以由不同的团队来管理，甚至可以使用不同的编程语言来编写。但仍然是一个完整的服务。

像**微服务**一样，一个前端应用，也可以按照一定的规则，拆分为不同的子应用，独立开发，独立部署，然后聚合成一个完整的应用面对客户。

### 微前端能带给我们什么

#### 简单、分离、松耦合的代码仓库

对比巨石应用一整块的代码仓库，微前端架构下的代码仓库更加**简单**、**轻量**。各个仓库的代码可以基于**业务**、**权限**、**变更的频率**、**组织结构**、**后端微服务**等原则拆分，**界限明确**，**降低耦合**，便于开发人员在开发过程中快速定位源代码，提高开发效率，降低维护成本。

#### 独立开发、独立部署

代码库拆分以后，我们可以基于各个代码仓库独立开发。由于代码体积的缩小，项目构建时间变短，极大提升开发效率。

另外，各个项目都有自己的交付流水线(从构建、测试到上线)，并且能够独立部署，不需要考虑其他项目的情况。

#### 技术栈无关

在实际项目中，各个项目会因为各种各样的原因导致使用的技术栈不一样。比如开发框架有 **react**、**vue**、**angular** 等，构建工具有 **webpack**、**rollup**、**parcel** 等，而且版本还可能不一致。使用微前端架构，可以做到将使用不同技术栈(不同版本)的子应用聚合起来

#### 遗留系统迁移

每个公司中，多多少少会存在一些应用是使用老的技术栈开发的，比如 Backbone、Vue1.0、angular2、jquery 等。这些应用已经在线上稳定运行，而且也没有新的功能。对于这样的应用，我们没有理由浪费时间和精力，可以通过微前端方案直接整合到新的应用中。

> **使用微前端方案很大一部分原因就是为了解决遗留系统迁移问题。**

#### 技术栈升级

除了遗留系统迁移，微前端在技术栈版本升级方面也能提供帮助。

有些项目，在成立之初使用了当前最新的技术如 antd2。随着技术的发展，antd 已经更新到了 4，但项目由于一直在迭代，还是使用 antd2。直接全部重构，肯定是不现实的，费时费力不说，风险也大。

针对这种情况，我们可以重起一个应用，使用 antd4 循序渐进的重构应用，然后使用微前端方案将新旧应用聚合在一起。

### 使用微前端时面临的挑战

- 子应用切换；
- 应用相互隔离，互不干扰；
- 子应用之间通信；
- 多个子应用并存；
- 用户状态的存储 - 免登；

### 微前端常用技术方案

目前，业界主流的微前端实现方案主要有：

- **路由分发式微前端**
- **iframe**
- **single-spa**
- **qiankun**
- **webpack5：module federation**
- **Web Component**

#### 路由分发式微前端

**路由分发式微前端**，即通过**路由**将不同的业务分发到不同的独立前端应用上。最常用的方案是通过 **HTTP 服务的反向代理**来实现。

下面是一个基于路由分发的 Nginx 配置：

```
 http {
        server {
            listen 80;
            server_name  xxx.xxx.com;
            location /api/ {
                proxy_pass http://localhost:3001/api;
            }
            location /web/admin {
                proxy_pass http://localhost:3002/api;
            }
            location / {
                proxy_pass /;
            }
        }
    }
```

通过上述配置，不同页面的请求就可以分发到不同的服务器上。

#### iframe

**iframe** 作为一项非常古老的技术，也可以用于实现**微前端**。通过 iframe，我们可以很方便的将一个应用嵌入到另一个应用中，而且两个应用之间的 css 和 javascript 是相互隔离的，不会互相干扰。

#### single-spa 

**路由转发模式**、**iframe 模式**尽管可以实现**微前端**，但是体验不好。我们每次切换回已经访问过的子应用时，都需要重新加载子应用，对性能有很大的影响。

我们知道，现在前端应用开发的主流模式为基于 **vue** / **react**/ **angular** 的**单页应用开发模式**。在这种模式下，我们需要维护一个**路由注册表**，每个**路由**对应各自的**页面组件 url**。**切换路由**时，如果是一个**新的页面**，需要**动态获取路由对应的 js 脚本**，然后执行脚本并渲染出对应的页面；如果是一个**已经访问过的页面**，那么直接**从缓存中获取已缓存的页面方法**，执行并渲染出对应的页面。

那么，**微前端**也有没有类似的实现方案，来获得和单页应用一样的用户体验呢？

答案是有的。 **single-spa** 提供了新的技术方案，可以帮忙我们实现类似**单页应用**的体验。

在 **single-spa** 方案中，应用被分为两类：**基座应用**和**子应用**。其中，**子应用**就是文章上面描述的需要聚合的子应用；而**基座应用**，是另外的一个单独的应用，用于**聚合子应用**。

和单页应用的实现原理类似，**single-spa** 会在**基座应用**中维护一个**路由注册表**，**每个路由对应一个子应用**。基座应用启动以后，当我们切换路由时，如果是一个新的子应用，会动态获取子应用的 js 脚本，然后执行脚本并渲染出相应的页面；如果是一个已经访问过的子应用，那么就会从缓存中获取已经缓存的子应用，激活子应用并渲染出对应的页面。

---

基座应用作为整个微前端应用中的项目调度中心，是用户进入该微前端应用时首先加载的部分。在主应用中，通过向single-spa提供的`registerApplication`函数传入指定的参数来注册子应用，这些参数包括子应用名称`name`、子应用如何加载`app`、子应用何时激活`activeWhen`、以及需要向子应用中传递的参数`customProps`等等。在完成整体注册后调用`start`函数启动整个微前端项目。

子应用是实际展示内容的部分，最主要的工作是导出single-spa中所规定的生命周期函数，以便于主应用调度。其中，bootstrap在子应用第一次加载时调用，mount在子应用每次激活时调用，unmount在子应用被移出时调用。此外在这些生命周期函数中我们可以看到props参数被传入，这个参数中包含了子应用注册名称、singleSpa实例、用户自定义参数等信息，方便子应用的使用。



#### qiankun

qiankun基于single-spa进行了二次开发，不但为用户提供了简便的接入方式（包括减少侵入性，易于老项目的改造），还贴心的提供了沙箱隔离以及实现了基于发布订阅模式的应用间通信方式，大大降低了微前端的准入门槛

**主应用：**

这里qiankun将single-spa中的app改为了entry并对其功能进行了增强，用户只需要输入子应用的html入口路径即可，其余加载工作由qiankun内部完成，当然也可以自行列出所需加载的资源。此外加入了container选项，让用户显示指定并感知到子应用所挂载的容器，简化了多个子应用同时激活的场景。

```javascript
import { registerMicroApps, start } from 'qiankun';

registerMicroApps([
  {
    name: 'react app', // app name registered
    entry: '//localhost:7100',
    container: '#yourContainer',
    activeRule: '/yourActiveRule',
  },
  {
    name: 'vue app',
    entry: { scripts: ['//localhost:7100/main.js'] },
    container: '#yourContainer2',
    activeRule: '/yourActiveRule2',
  },
]);

start();
```

**子应用：**

与single-spa基本一致，导出了三个生命周期函数。这里可以看到在mount中我们手动将react应用渲染到了页面上，反之在unmount中我们将其从页面上清除。

```javascript
/**
 * bootstrap 只会在微应用初始化的时候调用一次，下次微应用重新进入时会直接调用 mount 钩子，不会再重复触发 bootstrap。
 * 通常我们可以在这里做一些全局变量的初始化，比如不会在 unmount 阶段被销毁的应用级别的缓存等。
 */
export async function bootstrap() {
  console.log('react app bootstraped');
}

/**
 * 应用每次进入都会调用 mount 方法，通常我们在这里触发应用的渲染方法
 */
export async function mount(props) {
  ReactDOM.render(<App />, props.container ? props.container.querySelector('#root') : document.getElementById('root'));
}

/**
 * 应用每次 切出/卸载 会调用的方法，通常在这里我们会卸载微应用的应用实例
 */
export async function unmount(props) {
  ReactDOM.unmountComponentAtNode(
    props.container ? props.container.querySelector('#root') : document.getElementById('root'),
  );
}
```

可以看到，由于其帮助我们完成了子应用的加载工作，所以用户的配置相比于single-spa更为简便了。但是，除了这个明面上的工作，qiankun还在暗处为我们的易用性做出了很多努力，**接下来，我们会围绕着以下三个方面来深入剖析qiankun内部源码和相关实现原理：**

1. qiankun如何实现用户只需配置一个URL就可以加载相应子应用资源的；
2. qiankun如何帮助用户做到子应用间独立运行的（包括JS互不影响和CSS互不污染）；
3. qiankun如何帮助用户实现更简便高效的应用间通信的；

##### 子应用加载

qiankun的子应用注册方式非常简单，用户只需要调用registerMicroApps函数并将所需参数传入即可。qiankun在子应用加载上就是作为中间层存在的，其主要作用就是简化用户对于子应用注册的输入，qiankun中的路由监听和子应用生命周期管理实际上都是交给了single-spa来进行实现的。

为了方便使用，qiankun提供了基于url入口来加载子应用的方式。为了获取用户提供的html文件（或者资源文件数组）并解析出其中所需的资源，qiankun依赖了`import-html-entry`库中的相关方法，执行并得到了子应用导出的用户自定义生命周期。

对用户自定义的生命周期进行增强（包括挂载/卸载应用间的隔离沙箱，初始化或传入应用间通信方法等等），返回框架增强后的生命周期函数数组并注册在single-spa中。

##### 沙箱隔离

qiankun框架给我们提供的最便利和有用的功能就是其基于配置的自动化沙箱隔离机制了。有了框架层面的子应用隔离支持，用户无论是在编写JS代码还是修改CSS样式时都不必再担心代码对于全局环境的污染问题了。沙箱机制一方面提升了微应用框架运行的稳定性和独立性，另一方面也降低了微前端开发者的心智负担，让其只需专注于自己的子应用代码开发之中。

**JS隔离**

① **Snapshot沙箱**

该沙箱主要用于不支持Proxy对象的低版本浏览器之中，不能由用户手动指定该模式，qiankun会自动检测浏览器的支持情况并降级到Snapshot沙箱实现。由于这种实现方式在子应用运行过程中实际上修改了全局变量，因此不能用于多例模式之中（同时存在多个已挂载的子应用）。

沙箱内部存在两个对象变量`windowSnapshot`和`modifyPropsMap` ，分别用来存储子应用挂载前原始`window`对象上的全部属性以及子应卸载时被其修改过的`window`对象上的相关属性。

Snapshot沙箱会在子应用`mount`前将`modifyPropsMap`中存储的属性重新赋值给`window`以恢复该子应用之前执行时的全局变量上下文，并在子应用`unmount`后将`windowSnapshot`中存储的属性重新赋值给`window`以恢复该子应用运行前的全局变量上下文，从而使得两个不同子应用的`window`相互独立，达到JS隔离的目的。

② **Legacy沙箱**

当用户手动配置`sandbox.loose: true`时该沙箱被启用。Legacy沙箱同样会对`window`造成污染，但是其性能比要比snapshot沙箱好，因为该沙箱不用遍历window对象。同样legacy沙箱也只适用于单例模式之中。

Legacy沙箱为一个空对象`fakewindow`使用`proxy`代理拦截了其全部的set/get等操作，并在`loader`中用其替换了`window`。当用户试图修改`window`属性时，`fakewindow`上代理的`set`操作生效捕获了相关修改，其分别将新增的属性和修改前的值存入`addedPropsMapInSandbox`和`modifiedPropsOriginalValueMapInSandbox`这两个Map之中，此外还将所有修改记录在了`currentUpdatedPropsValueMap`之中，并改变了window对象。

这样当子应用挂载前，legacy沙箱会将`currentUpdatedPropsValueMap`之中记录的子应用相关修改重新赋予window，恢复其运行时上下文。当子应用卸载后，legacy沙箱会遍历`addedPropsMapInSandbox`和`modifiedPropsOriginalValueMapInSandbox`这两个Map并将window上的相关值恢复到子应用运行之前的状态。最终达到了子应用间JS隔离的目的。

③ **Proxy沙箱**

Proxy沙箱是qiankun框架中默认使用的沙箱模式（也可以通过配置`sandbox.loose: false`来开启），只有该模式真正做到了对window的无污染隔离（子应用完全不能修改全局变量），因此可以被应用在单/多例模式之中。

Proxy沙箱的原理也非常简单，它将window上的所有属性遍历拷贝生成一个新的fakeWindow对象，紧接着使用proxy代理这个fakeWindow，用户对window操作全部被拦截下来，只作用于在这个fakeWindow之上

---

**CSS隔离**

**① ShadowDOM**

当用户配置`sandbox.strictStyleIsolation: true`时，ShadowDOM样式沙箱会被开启。在这种模式下 qiankun 会为每个微应用的容器包裹上一个 [shadow dom](https://link.juejin.cn?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FWeb_Components%2FUsing_shadow_DOM) 节点，从而确保微应用的样式不会对全局造成影响。

这种方式虽然看起来清晰简单，还巧妙利用了浏览器对于ShadowDOM的CSS隔离特性，但是由于ShadowDOM的隔离比较严格，所以这并不是一种无脑使用的方案。例如：如果子应用内存在一个弹出时会挂在document根元素的弹窗，那么该弹窗的样式是否会受到ShadowDOM的影响而失效？所以开启该沙箱的用户需要明白自己在做什么，且可能需要对子应用内部代码做出一定的调整。

② **Scoped CSS**

因为ShadowDOM存在着上述的一些问题，qiankun贴心的为用户提供了另一种更加无脑简便的样式隔离方式，那就是Scoped CSS。通过配置`sandbox.experimentalStyleIsolation: true`，Scoped样式沙箱会被开启。

在这种模式下，qiankun会遍历子应用中所有的CSS选择器，通过对选择器前缀添加一个固定的带有该子应用标识的属性选择器的方式来限制其生效范围，从而避免子应用间、主应用与子应用的样式相互污染。

qiankun通过为子应用的外层包裹元素注入属性并将子应用全部样式的作用范围都限制在该包裹元素下（通过添加指定的属性选择器作为前缀）实现了scoped样式沙箱隔离。需要注意的是，如果用户在运行时对内联样式进行修改，qiankun是可以侦测到并帮助用户限制其作用范围，但如果用户在运行时引入了新的外联样式或者自行创建了新的内联标签，那么qiankun并不会做出反应，相关的CSS规则还是可能会污染全局样式。

##### 通信方式

`initGlobalState`函数的执行中完成了一个发布订阅模式的创建工作，并返回了相关的订阅/发布/注销方法。接着qiankun将这些返回的方法通过生命周期函数mount传递给子应用，这样子应用就能够拿到并使用全局状态了，从而应用间的通信就得以实现了。此外offGlobalStateChange会在子应用unmount时自动调用以解除该子应用的订阅，避免内存泄露。

#### webpack5：module federation

新发布的 **webpack5**，提供了一个新的特性 - **module federation**。基于这个特性，我们可以**在一个 javascript 应用中动态加载并运行另一个 javascript 应用的代码**，并实现**应用之间的依赖共享**。

通过 **module federation**，我们可以在一个应用里面动态渲染另一个应用的页面，这样也就实现了**多个子应用的聚合**。

#### Web Component

基于 **Web Component** 的 **Shadow Dom** 能力，我们也可以实现**微前端**，将多个子应用聚合起来。

- 自己写class，在js里生成一个要展示的组件的dom结构
- 把这个class用customElements.define跟dom里面的对应元素连接
- 写css，把css弄成内部样式
- 修改参数` mode` ，把Shadow DOM 封闭起来

可以看阮一峰的文章 https://www.ruanyifeng.com/blog/2019/08/web_components.html

感觉很像Vue的组件的思路

## 大前端

### 定义

简单来说，大前端就是所有前端的统称，比如Android、iOS、web、Watch等，最接近用户的那一层也就是UI层，然后将其统一起来，就是大前端。

大前端最大的特点在于一次开发，同时适用于所有平台，开发者不用为一个APP需要做Android和iOS两种模式而担心。大前端是web统一的时代，利用web不仅能开发出网站，更可以开发手机端web应用和移动端应用程序。

### 大前端为什么出现？

由于node的出现，前端工程师不需要依赖于后端程序而直接运行，从而前后端分离起来。

node，它做的最多的是渲染和api代理（bff），还有一些做rpc服务。它是大前端的基石，同时也拓宽了前端的领域，让前端更可控，更加应变。

所以当开发一个新产品的时候服务只需要写一次，但是面向用户的产品可能有很多，例如网站、Android客户端、iOS客户端和微信小程序等。由于各个平台使用的技术栈都不一样，代码无法复用，非常浪费人力、物力。

那么有没有什么技术能够解决这一痛点呢？大前端应运而生，其实大前端的主要核心就是跨平台技术，有了跨平台技术，各个平台的差异性就抹平了，开发者只需要一套技术栈就可以开发出适用于多个平台的客户端。

### 目前的前端

#### **前后端分离**

现在，**SPA 场景**下以及 **BFF 层**存在，前端不需要后端就能单独负责 view 的内容，让后端能真正脱离 view 专注于提供业务模型的 api，这是纵向的。

#### Node全栈

随着Node的出现，前端可以不用依赖后台人员，也不用学习新的后台语言，就可以轻松搞定后台的这部分事情。这样，面对一些小的系统，前端工程师就可以搞定整个系统。这部分体现了前端的全面性和全栈性。

#### 应对各种端

前端的涉猎范围变大，以前仅负责 PC 端浏览器，到如今网页，手机网页，公众号，PWA，移动端，客户端，小程序，只要哪写 JS 的地方，哪就是前端的工作。

## BFF

### BFF 缘由

最开始的时候前端只需要调用一个服务api就可以完成对应的业务。

后来，业务逻辑逐渐复杂。后端将复杂的业务分离成一个新的服务出来了。随着业务越来越复杂，后端需要拆分的业务也越来越多(**微服务化**)，这时候前端需要满足业务需求，一个功能不得不调用两个或多个微服务接口才能完成业务

这样的架构前端的代码实现必然会变得非常臃肿和繁杂，同时过多的请求可能也会导致网络性能瓶颈。所以为了解决这个问题，有人提出了`BFF层`。

简单地来说BFF就是：给前端服务的后端。他并不是技术，而是一种逻辑的分层。它位于后端微服务与前端之间，最直接的作用就是**对接处理前端的请求**。

### BFF 使用场景

BFF(Back-end For Front-end)是老生长谈的中间层概念，就是一层nodejs，能做请求转发和数据转化即可。

- 数据处理：字段名处理、数据结构处理、冗余数据处理
  - 缓存数据：BFF层对接的是前端请求，作为业务请求微服务的处理点，它还可以做数据的缓存。
  - 访问控制：服务中的权限控制，将所有服务中的权限控制集中在 BFF 层，使下层服务更加纯粹和独立。

- 接口聚合：让后端更注重服务基础能力的开发，更聚焦业务模型本身，见面的交互与逻辑由 `BFF` 层来完成

- 服务于多个终端，`Web` 端、H5 活动页、小程序、IOS、Android... 底层基础服务不需要考虑不同设备的兼容逻辑，这个需求前端同学更清楚

### BFF 利弊

#### 优点

- 利于前后端解耦，即便是后期有微服务迁移，也不需改动前端代码。
- **利于多端适配**
- 职能分工明确细化。留给后端更清晰的服务边界，只需要提供粗粒度的接口即可
- 利于提升前端体验和性能，琐碎的api由前端开发自己决定，更适配前端框架

#### 缺点

- 增多了数据流链路，不利于排查和定位问题
- 前端增加了开发工作量
- 增加了前后端开发人员的技术要求
- 增加了整体框架的复杂程度

## serverless

### 介绍

其实 Serverless 早已和前端产生了联系，只是我们可能没有感知。比如 CDN，我们把静态资源发布到 CDN 之后，就不需要关心 CDN 有多少个节点、节点如何分布，也不需要关心它如何做负载均衡、如何实现网络加速，所以 CDN 对前端来说是 Serverless。再比如对象存储，和 CDN 一样，我们只需要将文件上传到对象存储，就可以直接使用了，不需要关心它如何存取文件、如何进行权限控制，所以对象存储对前端工程师来说是 Serverless。甚至一些第三方的 API 服务，也是 Serverless，因为我们使用的时候，不需要去关心服务器。

当然，有了体感还不够，我们还是需要一个更精确的定义。从技术角度来说，Serverless 就是 FaaS 和 BaaS 的结合。

Serverless = FaaS + BaaS。

### 优势

在传统开发流程中，我们需要前端工程师写页面，后端工程师写接口。后端写完接口之后，把接口部署了，再进行前后端联调。联调完毕后再测试、上线。上线之后，还需要运维工程师对系统进行维护。整个过程涉及多个不同角色，链路较长，沟通协调也是一个问题。

而基于 Serverless，后端变得非常简单了，以往的后端应用被拆分为一个个函数，只需要写完函数并部署到 Serverless 服务即可，后续也不用关心任何服务器的运维操作。后端开发的门槛大幅度降低了。因此，只需要一个前端工程师就可以完成所有的开发工作。

### 使用

目前国内使用 Serverless 较多的场景可能就是小程开发了。具体的实现就是小程序云开发，支付宝小程序和微信小程序都提供了云开发功能。

### 感悟

现在不断的安利serverless，不要去神话它，有人也提到了，只是为了优化后端服务和运维部分，前端说白了，就只是使用而已，对于前端平常的开发，没有任何影响，没有云服务器，就直接调后端单机服务器或者公司服务器，万一出了问题，还得去找问题（一般服务器有问题，也不会让前端同学去找问题并解决，后端服务同理）。我觉得大家可以反过来想：

1、如果没有云说法，还会有“serverless”这种概念吗？

2、宣传某些观点出来的（不管是个人还是公司），看看背后到底再说什么？（可能跟钱、垄断或者真的是传播某些非常好的知识和观点等等）

3、对于目前的工作，有多少实际性的改变？（自己去体会，不敢说多）

## MongoDB

### **MongoDB是什么？**

MongoDB是一款为web应用程序和互联网基础设施设计的数据库管理系统。没错MongoDB就是数据库，是NoSQL类型的数据库

### 为什么要用MongoDB？

（1）MongoDB提出的是文档、集合的概念，使用BSON（类JSON）作为其数据模型结构，其结构是面向对象的而不是二维表，存储一个用户在MongoDB中是这样子的。

```text
{
    username:'123',
    password:'123'
｝
```

使用这样的数据模型，使得MongoDB能在生产环境中提供高读写的能力，吞吐量较于mysql等SQL数据库大大增强。

（2）易伸缩，自动故障转移。易伸缩指的是提供了分片能力，能对数据集进行分片，数据的存储压力分摊给多台服务器。自动故障转移是副本集的概念，MongoDB能检测主节点是否存活，当失活时能自动提升从节点为主节点，达到故障转移。

（3）数据模型因为是面向对象的，所以可以表示丰富的、有层级的数据结构，比如博客系统中能把“评论”直接怼到“文章“的文档中，而不必像myqsl一样创建三张表来描述这样的关系。

### 使用

可以直接用node.js 来对其做数据库操作

```
// 引入 mongodb
const {MongoClient} = require('mongodb');

// 定义数据库连接的地址
const url = 'mongodb://localhost:27017'; 
// const url = 'mongodb://admin:123456@localhost:27017/'; 有密码连接方式 admin 表示用户名，123456 表示密码

// 定义要操作的数据库
const dbName = 'itying';

MongoClient.connect(url, { useUnifiedTopology: true },(err,client)=>{
  if(err){
    console.log(err); 
    return; 
  }
  console.log("连接成功"); 
  // 获取 db 对象 
  const db = client.db(dbName); 

  // 操作完数据库后，一定要记得关闭
  client.close();
})
```

## 小程序

**微信小程序和支付宝小程序区别**

写法不一样：app.json（程序通用的的状态栏、导航条、标题、窗口背景色；tabBar）；pages后缀（视图层页面文件后缀、样式文件后缀）；一些事件函数要改名；条件渲染写法不同；提供的API不同（消息提示框等等）

## CI/CD



## ECMA2023

Draft ECMA-262 / February 27, 2023

### Array find from last

新增两个方法： `.findLast()`、`.findLastIndex()` 从数组的最后一个元素开始查找，可以同 `find()`、`findIndex()` 做一个对比。

```
const arr = [{ value: 1 }, { value: 2 }, { value: 3 }, { value: 4 }];

// find vs findLast
console.log(arr.find(n => n.value % 2 === 1)); // { value: 1 }
console.log(arr.findLast(n => n.value % 2 === 1)); // { value: 3 }

// findIndex vs findLastIndex
console.log(arr.findIndex(n => n.value % 2 === 1)); // 0
console.log(arr.findLastIndex(n => n.value % 2 === 1)); // 2
```

### 不改变数组自身，而是给返回值的数组方法

```
T.prototype.toReversed() -> T
T.prototype.toSorted(compareFn) -> t
T.prototype.toSpliced(start, deleteCount, ...items) -> T
T.prototype.with(index, value) -> T

const array = [1, 2, 3];
const newArray = array.with(1, false);
// [1, false, 3]
console.log(newArray);
// 原数组不变 [1, 2, 3]
console.log(array);
```

### WeakMap 支持 Symbol 作为 key

**WeakMap** 原本只支持 **object** 类型的 key，现在支持了 Symbol 类型作为 key。

### Hashbang Grammar

**Hashbang 语法是用来指定脚本文件的解释器是什么，语法规则是在脚本文件头部增加一行代码：**`#!/usr/bin/env node`。

```
// #!/usr/bin/env node
console.log("JavaScript");
```

# 进阶技能实战

## CSS 预处理器

### 介绍

CSS 预处理器是一种语言用来为 CSS 增加一些编程的的特性，无需考虑浏览器的兼容性问题，例如你可以在 CSS 中使用变量、简单的程序逻辑、函数等等在编程语言中的一些基本技巧，可以让CSS 更见简洁，适应性更强，代码更直观等诸多好处。

在使用 CSS 预处理器之前最重要的是理解语法，幸运的是基本上大多数预处理器的语法跟 CSS 都差不多。

**Sass**：2007年诞生，最早也是最成熟的CSS预处理器，拥有ruby社区的支持和compass这一最强大的css框架，目前受LESS影响，已经进化到了全面兼容CSS的**SCSS**。

> SCSS 是 Sass 3 引入新的语法，其语法完全兼容 CSS3，并且继承了 Sass 的强大功能。Sass 和 SCSS 其实是同一种东西，我们平时都称之为 Sass，两者之间不同之处有以下两点：
>
> 1. 文件扩展名不同，Sass 是以“.sass”后缀为扩展名，而 SCSS 是以“.scss”后缀为扩展名
> 2. 语法书写方式不同，**Sass 是以严格的缩进式语法规则来书写，不带大括号({})和分号(;)，而 SCSS 的语法书写和我们的 CSS 语法书写方式非常类似。SCSS 对空白符号不敏感，可以全写一行里面**

**Less**：2009年出现，受SASS的影响较大，但又使用CSS的语法，让大部分开发者和设计师更容易上手，在ruby社区之外支持者远超过SASS，其缺点是比起SASS来，可编程功能不够，不过优点是简单和兼容CSS，反过来也影响了SASS演变到了SCSS的时代，著名的Twitter Bootstrap就是采用LESS做底层语言的。

**Stylus**：2010年产生，来自Node.js社区，主要用来给Node项目进行CSS预处理支持，在此社区之内有一定支持者，在广泛的意义上人气还完全不如SASS和LESS。

#### Sass

Sass有两种语法，分别以「 *.sass 」和「 *.scss 」为扩展名。这里你可以查看[Sass 和 Scss 的异同](https://link.zhihu.com/?target=http%3A//sass.bootcss.com/docs/scss-for-sass-users/)。Sass 兼容 css ，你可以在 sass 文件里写 css，也可以严格按照 sass 的缩进方式省去「大括号」和「分号」，最终它们都会被编译成标准 css，比如：

```sass
/*style.sass*/
h1
  color: #666
  background-color: #666	
```

#### Less

Less 受 Sass 的影响非常大，以「 *.less 」为扩展名，是 sass 之后的又一款优秀的 css 预处理器。其特点包括：

- 变量：就像写其他语言一样，免于多处修改。
- 混合：class 之间的轻松引入和继承。
- 嵌套：选择器之间的嵌套使你的 less 非常简洁。
- 函数&运算：就像 js 一样，对 less 变量的操控更灵活。

比如这样的 Less

```css
@base: #f938ab;

.box-shadow(@style, @c) when (iscolor(@c)) {
  box-shadow:         @style @c;
  -webkit-box-shadow: @style @c;
  -moz-box-shadow:    @style @c;
}
.box-shadow(@style, @alpha: 50%) when (isnumber(@alpha)) {
  .box-shadow(@style, rgba(0, 0, 0, @alpha));
}
.box { 
  color: saturate(@base, 5%);
  border-color: lighten(@base, 30%);
  div { .box-shadow(0 0 5px, 30%) }
}
```

#### Stylus

相比于 sass 的激进和 less 的常规，Stylus 是一个高效、动态以及丰富的 CSS 预处理器。它同时支持缩进的和通俗的两种风格的 CSS 语法风格。

Stylus 扩展名为「 *.styl 」，跟另外两款 css 预处理器相比略显年轻，社区以及推广程度也不及 sass 和 less，但它的一些优秀特性同样令人着迷。

[Nib](https://link.zhihu.com/?target=https%3A//tj.github.io/nib/)是 Stylus 的应用的类库。给你的「 *.styl 」添加 Nib 的最快方式是克隆 Nib 的 Git 版本库并引入，因为有了 Nib，Stylus 的高效性才更为突出。

除了包含 Less 的一些优点，Stylus 在容错性上的突出特性也十分吸引我，你可以在一个 Stylus 文件里这样写，且它们都会被编译成标准 css：

```css
/*style.styl*/
/*类似于CSS标准语法*/
h1 {
  color: #963;
  background-color:#333;
}
/*省略大括号（｛｝）*/
h1 
  color: #963;
  background-color: #333;
/*省略大括号（｛｝）和分号（;）*/
h1
  color:#963
  background-color:#333
```

### 功能

#### **1.变量：**

可以把反复使用的css属性值 定义成变量，然后通过变量名来引用它们，而无需重复书写这一属性值。已经被赋值的变量以及其他的常量（如像素、颜色等）可以参与运算。

- Sass声明变量必须是『$』开头，后面紧跟变量名和变量值，而且变量名和变量值需要使用冒号：分隔开。
- Less 声明变量用『@』开头，其余等同 Sass。
- Stylus 中声明变量没有任何限定，结尾的分号可有可无，但变量名和变量值之间必须要有『等号』，但 不要使用『@』声明变量。Stylus 调用变量的方法和Less、Sass完全相同。

#### **2.作用域：**

css 预编译器把变量赋予作用域，也就是存在生命周期。就像 js 一样，它会先从局部作用域查找变量，依次向上级作用域查找。

- Sass：三者最差，不存在全局变量的概念。也就是说在 Sass 中定义了相同名字的变量时你就要小心蛋疼了。
- Less：我认为跟 JS 一样，逐级查找，向上冒泡。
- Stylus：完全等同 Less。Stylus 和 Sass 则更倾向于指令式。

#### **3.嵌套：**

如果我们需要在CSS中相同的 parent 引用多个元素，这将是非常乏味的，你需要一遍又一遍地写 parent。

如果用 CSS 预处理器，就可以少写很多单词，而且父子节点关系一目了然，并且sass，Less，stylus都支持下面这样的写法，且都是相同的：

```
//scss style //----------------------------------- 
nav { 
    ul { 
       margin: 0; 
       padding: 0; 
    } 
    li { 
       display: inline-block; 
    } 
    a { 
       display: block; 
       padding: 6px 12px; 
       text-decoration: none; 
    } 
}
//css style //----------------------------------- 
nav ul { 
    margin: 0; 
    padding: 0; 
    list-style: none; 
} 
nav li { 
    display: inline-block; 
} 
nav a { 
    display: block; 
    padding: 6px 12px; 
    text-decoration: none; 
}
```

这样做是非常方便的，也很直观。

#### **4.继承：**

css 属性的继承是一个非常重要的特性，好消息是三种预编译器都对此做出了改善。

- Sass和Stylus的继承非常像，能把一个选择器的所有样式继承到另一个选择器上。使用『@extend』开始，后面接被继承的选择器。

```sass
.shit {
  margin: 10px 5px;
  padding: 2px;
}
p {
  @extend .shit;/*继承.block*/
  border: 1px solid #aaa;
}
ul,li {
  @extend .shit; /*继承.block*/
  color: #aaa;
}
```

将被编译成标准 css：

```css
.shit,p,ul,ol {
  margin: 10px 5px;
  padding:2px;
}
p {
  border: 1px solid #aaa
}
ul,li {
  color:#aaa;
}
```

- Less 继承：在这方面 Less 表现的稍微弱一些，更像是混入写法：将Mixins中的样式嵌套到每个选择器里面。然而这样会带来一个明显的缺点：每个选择器中会出现重复的样式。

```
.message {
  border: 1px solid #ccc;
  padding: 10px;
  color: #333;
}
.success {
  .message;
  border-color: green;
}
.error {
  .message;
  border-color: red;
}
.warning {
  .message;
  border-color: yellow;
}
```



#### **5.运算**

在 CSS 预处理器中还是可以进行样式的计算如下：

```
body {
  margin: (14px/2);
  top: 50px + 100px;
  right: 80 * 10%;
}
```

在sass，Lessstylus中都是可以这样做的。

#### 6.颜色函数

CSS 预处理器一般都会内置一些颜色处理函数用来对颜色值进行处理，例如加亮、变暗、颜色梯度等。

**sass的颜色处理函数：**

```scss
lighten($color, 10%); 
darken($color, 10%);  
saturate($color, 10%);   
desaturate($color, 10%);
grayscale($color);  
complement($color); 
invert($color); 
mix($color1, $color2, 50%);
```

#### 7.Mixins（混入）

Mixins 有点像是函数或者是宏，当某段 CSS 经常需要在多个元素中使用时，可以为这些共用的 CSS 定义一个 Mixin，然后只需要在需要引用这些 CSS 地方调用该 Mixin 即可。

**1.Sass 的混入语法：**

sass中可用mixin定义一些代码片段，且可传参数，方便日后根据需求调用。比如说处理css3浏览器前缀：

```scss
@mixin error($borderWidth: 2px) {
  border: $borderWidth solid #F00;
  color: #F00;
}
.generic-error {
  padding: 20px;
  margin: 4px;
  @ include error(); //这里调用默认 border: 2px solid #F00;
}
.login-error {
  left: 12px;
  position: absolute;
  top: 20px;
  @ include error(5px); //这里调用 border:5px solid #F00;
}
```

**2.Less CSS 的混入语法：**
less也支持带参数的混合以及有默认参数值的混合，如下面的例子所示：

```less
.error(@borderWidth: 2px) {
  border: @borderWidth solid #F00;
  color: #F00;
}
.generic-error {
  padding: 20px;
  margin: 4px;
  .error(); //这里调用默认 border: 2px solid #F00
}
.login-error {
  left: 12px;
  position: absolute;
  top: 20px;
  .error(5px); //这里调用 border:5px solid #F00;
}
```

**Stylus 的混入语法：**

```stylus
error(borderWidth= 2px) {
  border: borderWidth solid #F00;
  color: #F00;
}
.generic-error {
  padding: 20px;
  margin: 4px;
  error(); 
}
.login-error {
  left: 12px;
  position: absolute;
  top: 20px;
  error(5px); 
}
```

他们最终呈现的效果都如下：

```css
.generic-error {
  padding: 20px;
  margin: 4px;
  border: 2px solid #f00;
  color: #f00;
}
.login-error {
  left: 12px;
  position: absolute;
  top: 20px;
  border: 5px solid #f00;
  color: #f00;
}
```

### 高级语法

1.在sass中，还支持条件语句：

```scss
@if可一个条件单独使用，也可以和@else结合多条件使用
```

代码如下：

```
$lte7: true;
$type: monster;
.ib{
    display:inline-block;
    @if $lte7 {
        *display:inline;
        *zoom:1;
    }
}
p {
  @if $type == ocean {
    color: blue;
  } @else if $type == matador {
    color: red;
  } @else if $type == monster {
    color: green;
  } @else {
    color: black;
  }
}
```

2.除却条件语句，sass还支持for循环：

for循环有两种形式，分别为：

```scss
1.@for $var from <start> through <end>
2.@for $var from <start> to <end>。
```

其中$i表示变量，start表示起始值，end表示结束值，这两个的区别是关键字through表示包括end这个数，而to则不包括end这个数。

```scss
@for $i from 1 to 10 {
  .border-#{$i} {
    border: #{$i}px solid blue;
  }
}
```

同时也支持while循环

## TypeScript

### 简介

Type + JavaScript

### 常见问题

interface和type区别

## Vite

### 简介

> Vite，一个基于**浏览器原生 ES imports** 的开发服务器。利用浏览器去解析 imports，在服务器端按需编译返回，完全**跳过了打包这个概念**，服务器随起随用。同时不仅有 Vue 文件支持，还搞定了**热更新**，而且热更新的速度不会随着模块增多而变慢。针对生产环境则可以把同一份代码用 rollup 打。虽然现在还比较粗糙，但这个方向我觉得是有潜力的，做得好可以彻底解决改一行代码等半天热更新的问题。

 vite 主要特点是基于浏览器 native 的 ES module 来开发，省略打包这个步骤，因为需要什么资源直接在浏览器里引入即可。基于浏览器 ES module 来开发 web 应用也不是什么新鲜事，snowpack 也基于此**（vite对标Snowpack）**，不过目前此项目社区中并没有流行起来，vite 的出现也许会让这种开发方式再火一阵子。

有趣的是 vite 算是革了 webpack 的命了（生产环境用 rollup）

Vite 的核心能力和 `webpack` +` webpack-dev-server` 相似，但是在开发者体验上有一些提升：

- 无论项目大小有多大，启动应用都只需更少的时间；
- 无论项目大小有多大，`HMR（Hot Module Replacing）`热更新都可以做到及时响应；
- 按需编译；
- 零配置，开箱即用；
- Esbuild 能力带来的 Typescript/jsx 的原生支持。

### 优势

#### 解决webpack的痛点

vue-cli内置webpack，所以vite用来替换了vue-cli

当项目体积越来越庞大时，构建工具需要处理的代码量呈指数级增长，包含数千个模块的项目也是相当普遍。类似 Webpack 的构建工具就会遇到性能瓶颈：通常需要很长时间，甚至几分钟项目才能启动起来。热更新（HMR）也可能需几秒，甚至十几秒。**Webpack 启动后会做一堆事情，经历一条很长的编译打包链条，从入口开始需要逐步经历语法解析、依赖收集、代码转译、打包合并、代码优化，最终将高版本的、离散的源码编译打包成低版本、高兼容性的产物代码，这可满满都是 CPU、IO 操作啊**，在 Node 运行时下性能必然是有问题。

当然，开发者做了很多努力，但是webpack优化余地有限。为了减少 bundle 大小，会使用动态引入 `import()` 的方式异步的加载模块（ 被引入模块依然需要提前打包)，又或者使用 tree shaking 等方式尽力的去掉未引用的模块。

这些方式都不如 vite 的优雅，vite 可以只在需要某个模块的时候动态（借助 `import()` ）的引入它， Vite 在开发模式下并没有做太多打包操作！ Vite 运行 Dev 命令后只做了两件事情，一是启动了一个用于承载资源服务的 service；二是使用 [esbuild](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/BCL1Cm64mps4cZe_V26Wtw) 预构建 npm 依赖包。之后就一直躺着，直到浏览器以 http 方式发来 ESM 规范的模块请求时，Vite 才开始“**「按需编译」**”被请求的模块。

#### 其它性能优化

除了启动阶段跳过编译操作之外，Vite 还有很多值得一提的性能优化，整体梳理一下：

- 预编译：npm 包这类基本不会变化的模块，使用 Esbuild 在 **「预构建」** 阶段先打包整理好，减少 http 请求数。并且`esbuild` 使用 Go 编写，比用 JS 编写的打包器预构建依赖快 10-100 倍。
- 按需编译：用户代码这一类频繁变动的模块，直到被使用时才会执行编译操作
- 客户端强缓存：请求过的模块会被以 http 头 `max-age=31536000,immutable` 设置为强缓存，如果模块发生变化则用附加的版本 query 使其失效
- 产物优化：相比于 Webpack ，Vite 直接锚定高版本浏览器，不需要在 build 产物中插入过多运行时与模板代码
- 内置更好的分包实现：不需要用户干预，默认启用一系列智能分包规则，尽可能减少模块的重复打包
- 更好的静态资源处理：Vite 尽量避免直接处理静态资源，而是选择遵循 ESM 方式提供服务，例如引入图片 `import img from 'xxx.png'` 语句，执行后 `img` 变量只是一个路径字符串。

### 总结

Vite 的表现很容易让人联想到 vue-cli，不过两者区别还是挺大的：vue-cli 底层依赖 Webpack，实际的构建工作通常由各种 Webpack loader、plugin 实现，比如 less => css 由 less-loader 实现；图片加载由 img-loader 实现等。这套设计很灵活，你可以在 Webpack 体系下做任何你能想到的变更，只需要学习一点点 Webpack 的知识，包括百来个配置项、成千上万的插件、若干虚无缥缈的构建概念等。

而 Vite 显得特别简洁，它只是暴露了极少数的配置项与 plugin 接口，设计上就没打算让你做太多自定义操作。。。这是因为 Vite 从一开始就没打算做成另一个 Webpack，而是做成一套“能够显著提升前端开发体验的前端构建工具”，重在 **「开发体验」** 啊同学们，Vite 可谓是用心良苦，想尽办法降低学习入门成本，它就不希望你为了使用工具又学一大堆复杂、缥缈的概念，希望这些事情都在框架层面屏蔽了 —— 虽然代价是丧失灵活性。

简单说吧，Vite 定位就是傻瓜式但强大的构建工具，你专心写好业务代码，早点下班，不用再为了工具费神费力了。

**Vite 对已有生态的兼容性**也不容忽略，主要体现在两个点：

- 与 Vue 解耦，兼容支持 React、Svelte、Preact、Vanilla 等，这意味着 Vite 可以被应用在大多数现代技术栈中
- 与 Rollup 极其接近的插件接口，这意味着可以复用 Rollup 生态中大部分已经被反复锤炼的工具

## 可视化库

### D3.js

### Echart

## 跨端

### 介绍

随着业务的发展，产生了越来越多的业务场景，同时随着技术的发展，产生了越来越多的端，PC 端（Windows、Mac），移动端（安卓、iOS）、web 端、IoT 设备（车载设备、手表）等

**常见痛点**

1. 各端功能几乎一致，各端需要单独配置研发人员 
2. 开发、维护成本高
3. 安卓、iOS 发版周期长

**目标**

底层抹平差异，提升开发效率

使得用户体验依然好——稳定性好，性能体验好

### 技术方案

#### Electron类方案

这类方案最为直接，简单来说就是用网页来跨端。由于我们绝大多数端上（甚至包括封闭的小程序生态）都支持 Webview，所以只要开发网页然后投放到多个端即可，在桌面端对应的方案就是 Electron。

#### ReactNative

移动平台上尤其是早期 WebView 的性能体验非常糟糕，前面我们也提到这种差距主要来自于 Web 生态本身沉重的历史负担。

React-Native这类方案通过尽可能的取长补短，通过结合 Web 的生态和 Native 的组件，让 JS 执行代码后用 Native 的组件进行渲染。由于抛弃了 Web 的历史包袱，这类方案可以做一些大刀阔斧的改动。比如抛弃 CSS 中的大量标准，只支持部分 flex 布局能力来减少布局和渲染的复杂度。

#### Flutter

Flutter 要解决的问题和上面的方案不同，完全不打算继续在 Web 生态上借力，从设计之初也并没有把 Web 生态考虑进去。相比于 RN 依赖 Native View 渲染，Flutter 则是自绘的组件，直接通过 Skia 绘制到屏幕上。

由于可以完全发挥 GPU 的能力，也不需要去 Native 绕一圈。Flutter 理论上能做到更好的性能和两端一致性，这一意味着理论上未来可能基于 Flutter 的 JS 动态化方案能够在样式上支持的比 WEEX 更好。

## Electron

## Pinia

## Git

一般来说，Git 的工作流程分为以下几步

```bash
1.在工作区开发，添加，修改文件。
2.将修改后的文件放入暂存区。
3.将暂存区域的文件提交到本地仓库。
4.将本地仓库的修改推送到远程仓库。
```

### 创建仓库

创建本地仓库的方法有两种：

- 一种是创建全新的仓库：`git init`，会在当前目录初始化创建仓库。
- 另一种是克隆远程仓库：`git clone [url]`



### 暂存区

可以简单理解为，`git add`命令就是把要提交的所有修改放到暂存区（Stage），然后，执行`git commit`就可以一次性把暂存区的所有修改提交到仓库。

#### git add

添加文件到暂存区

```bash
# 添加某个文件到暂存区，后面可以跟多个文件，以空格区分
git add xxx
# 添加当前更改的所有文件到暂存区。
git add .
```

#### git commit

```bash
# 提交暂存的更改，会新开编辑器进行编辑
git commit 
# 提交暂存的更改，并记录下备注
git commit -m "you message"
# 等同于 git add . && git commit -m
git commit -am
# 对最近一次的提交的信息进行修改,此操作会修改commit的hash值
git commit --amend
```

#### git stash

可以把当前**工作区、暂存区** 未提交的内容“隐藏”起来，就像什么都没发生一样。

当然这里先提交到本地也是可以的，只是提交不是一个完整的功能代码，而是残缺的一部分，影响也不大。

### 版本库

#### git log、git reflog

每一个提交都有一个唯一标识，主要就是提交的`hash`值`commit id`，在很多指令中会用到，如版本回退、拣选提交等，需要指定一个提交。那标识唯一提交有两种方式：

- 首先就是`commit id`，一个40位编码，指令中使用的时候可以只输入前几位（6位）即可。
- 还有一种就是 HEAD~n，是基于当前HEAD位置的一个相对坐标。
  - `HEAD` 表示当前分支的最新版本，是比较常用的参数。
  - `HEAD^`上一个版本，`HEAD^^` 上上一个版本。
  - `HEAD~` 或`HEAD~1` 表示上一个版本，以此类推，`HEAD^10` 为最近第10个版本。
  - `HEAD@{2}`在`git reflog`日志中标记的提交记录索引。

通过`git log`、`git reflog`可以查看历史日志，可以看每次提交的唯一编号（hash）。区别是`git reflog`可以查看所有操作的记录（实际是HEAD变更记录），包括被撤销回退的提交记录。

#### git diff

比较不同文件版本之间的差异。

| **指令**                 | **描述**                                                     |
| ------------------------ | ------------------------------------------------------------ |
| **git diff**             | 查看暂存区和工作区的差异                                     |
| git diff [file]          | 同上，指定文件                                               |
| git diff --cached        | 查看已暂存的改动，就是暂存区与新版本`HEAD`进行比较           |
| git diff --staged        | 同上                                                         |
| git diff --cached [file] | 同上，指定文件                                               |
| git diff HEAD            | 查看已暂存的+未暂存的所有改动，就是与最新版本`HEAD`进行比较  |
| git diff HEAD~           | 同上，与上一个版本比较。`HEAD~`表示上一个版本，`HEAD~10`为最近第10个版本 |
| git diff [id] [id]       | 查看两次提交之间的差异                                       |
| git diff [branch]        | 查看工作区和分支直接的差异                                   |

在有冲突的文件中，`<<<<<<< HEAD`开头的内容就表示是有冲突的部分。`=======`分割线上方是当前分支的内容，下方是被合并分支的变更内容。

#### git tag

**标签**（Tags）指的是某个分支某个特定时间点的状态，是对某一个提交记录的的**固定**“指针”引用。一经创建，不可移动，存储在工作区根目录下`.git\refs\tags`。可以理解为某一次提交（编号）的别名，常用来标记版本。

所以发布时，一般都会打一个版本标签，作为该版本的快照，指向对应提交`commit`。比如我们今天终于完成了V1.1版本的开发、测试，并成功上线了，那就可给今天最后这个提交打一个标签“V1.1”，便于版本管理。

标签总是和某个commit挂钩。如果这个commit既出现在master分支，又出现在dev分支，那么在这两个分支上都可以看到这个标签。

#### git reset

`reset`是专门用来撤销修改、回退版本的指令，支持的场景比较多，多种撤销姿势，所以参数组合也比较多。简单理解就是移动`master`分支、`HEAD`的“指针”地址，理解这一点就基本掌握`reset`了。

`reset`有三种模式，对应三种参数：`mixed`（默认模式）、`soft`、`hard`。三种参数的主要区别就是对工作区、暂存区的操作不同。

- `mixed`为默认模式，参数可以省略。
- 只有`hard`模式会重置工作区、暂存区，一般用这个模式会多一点。

#### git revert

安全的撤销某一个提交记录，基本原理就是生产一个新的提交，用原提交的逆向操作来完成撤销操作。注意，这不同于`reset`，`reset`是回退版本，revert只是用于撤销某一次历史提交，操作是比较安全的



### 远程库

#### git remote

为了便于管理，Git要求每个远程主机都必须指定一个主机名。`git remote`命令就用于管理主机名。

不带选项的时候，`git remote`命令列出所有远程主机。

> ```javascript
> $ git remote
> origin
> ```

使用`-v`选项，可以参看远程主机的网址。

> ```javascript
> $ git remote -v
> origin  git@github.com:jquery/jquery.git (fetch)
> origin  git@github.com:jquery/jquery.git (push)
> ```

上面命令表示，当前只有一台远程主机，叫做origin，以及它的网址。

克隆版本库的时候，所使用的远程主机自动被Git命名为`origin`。如果想用其他的主机名，需要用`git clone`命令的`-o`选项指定。



#### git pull

命令的作用是，取回远程主机某个分支的更新，再与本地的指定分支合并。它的完整格式稍稍有点复杂。

> ```javascript
> $ git pull <远程主机名> <远程分支名>:<本地分支名>
> ```

比如，取回`origin`主机的`next`分支，与本地的`master`分支合并，需要写成下面这样。

> ```javascript
> $ git pull origin next:master
> ```

如果远程分支是与当前分支合并，则冒号后面的部分可以省略。

> ```javascript
> $ git pull origin next
> ```

上面命令表示，取回`origin/next`分支，再与当前分支合并。实质上，这等同于先做`git fetch`，再做`git merge`。

> ```javascript
> $ git fetch origin
> $ git merge origin/next
> ```

在某些场合，Git会自动在本地分支与远程分支之间，建立一种追踪关系（tracking）。比如，在`git clone`的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的`master`分支自动"追踪"`origin/master`分支。

Git也允许手动建立追踪关系。

> ```javascript
> git branch --set-upstream master origin/next
> ```

上面命令指定`master`分支追踪`origin/next`分支。

如果当前分支与远程分支存在追踪关系，`git pull`就可以省略远程分支名。

> ```javascript
> $ git pull origin
> ```

上面命令表示，本地的当前分支自动与对应的`origin`主机"追踪分支"（remote-tracking branch）进行合并。

如果当前分支只有一个追踪分支，连远程主机名都可以省略。

> ```javascript
> $ git pull
> ```

上面命令表示，当前分支自动与唯一一个追踪分支进行合并。

如果合并需要采用rebase模式，可以使用`--rebase`选项。

> ```javascript
> $ git pull --rebase <远程主机名> <远程分支名>:<本地分支名>
> ```

如果远程主机删除了某个分支，默认情况下，`git pull` 不会在拉取远程分支的时候，删除对应的本地分支。这是为了防止，由于其他人操作了远程主机，导致`git pull`不知不觉删除了本地分支。



#### git fetch

与 `git pull` 不同的是 `git fetch` 操作仅仅只会拉取远程的更改，不会自动进行 merge 操作。对你当前的代码没有影响

```bash
# 获取远程仓库特定分支的更新
git fetch <远程主机名> <分支名>
# 获取远程仓库所有分支的更新
git fetch --all
```

#### git push

命令用于将本地分支的更新，推送到远程主机。它的格式与`git pull`命令相仿。

> ```javascript
> $ git push <远程主机名> <本地分支名>:<远程分支名>
> ```

注意，分支推送顺序的写法是<来源地>:<目的地>，所以`git pull`是<远程分支>:<本地分支>，而`git push`是<本地分支>:<远程分支>。

如果省略远程分支名，则表示将本地分支推送与之存在"追踪关系"的远程分支（通常两者同名），如果该远程分支不存在，则会被新建。

> ```javascript
> $ git push origin master
> ```

上面命令表示，将本地的`master`分支推送到`origin`主机的`master`分支。如果后者不存在，则会被新建。



不带任何参数的`git push`，默认只推送当前分支，这叫做simple方式。此外，还有一种matching方式，会推送所有有对应的远程分支的本地分支。Git 2.0版本之前，默认采用matching方法，现在改为默认采用simple方式。如果要修改这个设置，可以采用`git config`命令。

> ```javascript
> $ git config --global push.default matching
> # 或者
> $ git config --global push.default simple
> ```



如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做`git pull`合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用`--force`选项。

> ```javascript
> $ git push --force origin 
> ```

上面命令使用`--force`选项，结果导致远程主机上更新的版本被覆盖。除非你很确定要这样做，否则应该尽量避免使用`--force`选项。而应该先把远端当前分支的代码拉下来，解决一下冲突



### 本地分支

#### git branch

```bash
# 新建本地分支，但不切换
git branch <branch-name> 
# 查看本地分支
git branch
# 查看远程分支
git branch -r
# 查看本地和远程分支
git branch -a
# 删除本地分支
git branch -D <branch-nane>
# 重新命名分支
git branch -m <old-branch-name> <new-branch-name>
```

#### git checkout

使用 `git checkout dev`切换分支时，干了两件事：

- `HEAD`指向`dev`：修改`HEAD`的“指针”引用，指向`dev`分支。
- 还原工作空间：把`dev`分支内容还原到工作空间。

#### git merge、git rebase

把两个分支的修改内容合并到一起，常用的合并指令`git merge [branch]`，将分支`[branch]`合并到当前分支。根据要合并的内容的不同，具体合并过程就会有多种情况。

- **快速合并（Fast forward）**

`master`分支么有任何提交，“`git merge dev`”合并分支`dev`到`master`，此时合并速度就非常快，直接移动`master`的“指针”引用到`dev`即可。这就是快速合并（Fast forward），不会产生新的提交。

- **普通合并**

如果`master`有变更，存在分支交叉，则会把两边的变更合并成一个提交。

- 如果两边变更的文件不同，没有什么冲突，就自动合并了。
- 如果有修改同一个文件，则会存在冲突，到底该采用哪边的，程序无法判断，就换产生冲突。冲突内容需要人工修改后再重新提交，才能完成最终的合并。

在有冲突的文件中，`<<<<<<< HEAD`开头的内容就表示是有冲突的部分，需要人工处理，可以借助一些第三方的对比工具。人工处理完毕后，完成合并提交，才最终完成此次合并。`=======`分割线上方是当前分支的内容，下方是被合并分支的变更内容。

**rebase 和 merge 的区别**

`merge` 和 `rebase`作用都是一样的，区别是`rebase`的提交历史更简洁，干掉了分叉，merge的提交历史更完整。

rebase 先是逐个应用了 feature/1 分支的更改，然后以 feature/1分支最后的提交作为基点，再逐个应用 feature/2 的每个更改。

而`git merge` 在不是 fast-forward（快速合并）的情况下，会产生一条额外的合并记录，类似 `Merge branch 'xxx' into 'xxx'` 的一条提交信息。

在解决冲突的时候，用 merge 只需要解决一次冲突即可，简单粗暴，而用 rebase 的时候 ，需要依次解决每次的冲突，才可以提交。



### 开发经验

**主分支：master**，稳定版本代码分支，对外可以随时编译发布的分支，不允许直接Push代码，只能请求合并（pull request），且只接受`hotfix`、`release`分支的代码合并。

**热修复分支：hotfix**，针对线上紧急问题、bug修复的代码分支，修复完后合并到主分支、开发分支。

- ① 切换到`hotfix`分支，从`master`更新代码；
- ② 修复bug；
- ③ 合并代码到`dev`分支，在本地Git中操作即可；
- ④ 合并代码到`master`分支。

**发版分支：release**，版本发布分支，用于迭代版本发布。迭代开发完成后，合并`dev`代码到`release`，在`release`分支上编译发布版本，以及修改bug（定时同步bug修改到`dev`分支）。测试完成后此版本可以作为发版使用，然后把稳定的代码push到`master`分支，并打上版本标签。

**开发分支：dev**，开发版本分支，针对迭代任务开发的分支，日常开发原则上都在此分支上面，迭代完成后合并到release分支，开发、发版两不误。